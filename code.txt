Code for Simple Linear Regression: 
import pandas as pd 
import matplotlib.pyplot as plt 
from sklearn.datasets import fetch_california_housing 
from sklearn.model_selection import train_test_split 
from sklearn.linear_model import LinearRegression 
from sklearn.metrics import mean_squared_error, r2_score 
data = fetch_california_housing(as_frame=True) 
df = data.frame 
# Use only one feature: Median Income 
X = df[['MedInc']]  # Independent variable 
y = df['MedHouseVal']  # Dependent variable (target) 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) 
model = LinearRegression() 
model.fit(X_train, y_train) 
y_pred = model.predict(X_test) 
mse = mean_squared_error(y_test, y_pred) 
r2 = r2_score(y_test, y_pred) 
print("Simple Linear Regression - California Housing Dataset (MedInc → MedHouseVal)") 
print(f"Mean Squared Error (MSE): {mse:.4f}") 
print(f"R² Score: {r2:.4f}") 
plt.figure(figsize=(8, 6)) 
plt.scatter(X_test, y_test, color='blue', edgecolors='black', alpha=0.4, label='Actual Points') 
plt.plot(X_test, y_pred, color='red', linewidth=2, label='Regression Line') 
plt.xlabel('Median Income (in $10,000s)') 
plt.ylabel('Median House Value (in $100,000s)') 
plt.title('Simple Linear Regression: Income vs House Value') 
plt.legend() 
plt.grid(True) 
plt.tight_layout() 
plt.show() 


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Code for Multiple Linear Regression: 
import pandas as pd 
import matplotlib.pyplot as plt 
from sklearn.datasets import fetch_california_housing 
from sklearn.model_selection import train_test_split 
from sklearn.linear_model import LinearRegression 
from sklearn.metrics import mean_squared_error, r2_score 
data = fetch_california_housing(as_frame=True) 
df = data.frame 
X = df.drop(columns='MedHouseVal') 
y = df['MedHouseVal']  # Median house value (in $100,000s) 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) 
model = LinearRegression() 
model.fit(X_train, y_train) 
y_pred = model.predict(X_test) 
mse = mean_squared_error(y_test, y_pred) 
r2 = r2_score(y_test, y_pred) 
print("Multiple Linear Regression - California Housing Dataset") 
print(f"Mean Squared Error (MSE): {mse:.4f}") 
print(f"R² Score: {r2:.4f}") 
plt.figure(figsize=(8, 6)) 
plt.scatter(y_test, y_pred, color='blue', edgecolors='black', alpha=0.5, label='Predicted Points') 
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2, label='Perfect Prediction Line') 
plt.xlabel('Actual Median House Value ($100,000s)') 
plt.ylabel('Predicted Median House Value ($100,000s)') 
plt.title('Actual vs Predicted House Prices') 
plt.legend(loc='upper left') 
plt.grid(True) 
plt.tight_layout() 
plt.show()

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

PCA
import numpy as np 
import matplotlib.pyplot as plt 
from sklearn.datasets import load_iris 
from sklearn.decomposition import PCA 
from sklearn.preprocessing import StandardScaler 
iris = load_iris() 
X = iris.data  # Features 
y = iris.target  # Labels 
target_names = iris.target_names 
X_std = StandardScaler().fit_transform(X) 
pca = PCA(n_components=2) 
X_pca = pca.fit_transform(X_std) 
print("Explained variance ratio:", pca.explained_variance_ratio_) 
plt.figure(figsize=(8, 6)) 
colors = ['red', 'green', 'blue'] 
for color, i, target_name in zip(colors, [0, 1, 2], target_names): 
plt.scatter(X_pca[y == i, 0], X_pca[y == i, 1], color=color, lw=2, label=target_name) 
plt.xlabel('Principal Component 1') 
plt.ylabel('Principal Component 2') 
plt.title('PCA on Iris Dataset') 
plt.legend() 
plt.grid(True) 
plt.show() 



++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Code for Principal Component Analysis (PCA) for Non – Linear Dimensionality: 
import matplotlib.pyplot as plt 
from sklearn.datasets import load_iris 
from sklearn.decomposition import KernelPCA 
from sklearn.preprocessing import StandardScaler 
iris = load_iris() 
X = iris.data 
y = iris.target 
scaler = StandardScaler() 
X_scaled = scaler.fit_transform(X) 
kpca = KernelPCA(n_components=2, kernel="rbf", gamma=15) 
X_kpca = kpca.fit_transform(X_scaled) 
plt.figure(figsize=(12,5)) 
plt.subplot(1,2,1) 
plt.scatter(X_scaled[:,0], X_scaled[:,1], c=y, cmap=plt.cm.Set1, s=40) 
plt.title("Iris Dataset (first 2 features)") 
plt.subplot(1,2,2) 
plt.scatter(X_kpca[:,0], X_kpca[:,1], c=y, cmap=plt.cm.Set1, s=40) 
plt.title("Iris Dataset after Kernel PCA (RBF kernel)") 
plt.show()

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Code for Fuzzy set and its operation: 
import numpy as np 
import matplotlib.pyplot as plt 
X = np.linspace(0, 10, 100) 
A = np.maximum(0, np.minimum((5 - X) / 5, 1)) 
B = np.maximum(0, np.minimum((X - 5) / 5, 1)) 
fuzzy_union = np.maximum(A, B) 
fuzzy_intersection = np.minimum(A, B) 
fuzzy_complement_A = 1 - A 
fuzzy_difference = np.minimum(A, 1 - B) 
plt.figure(figsize=(10, 6)) 
plt.plot(X, A, label='Fuzzy Set A', color='blue') 
plt.plot(X, B, label='Fuzzy Set B', color='orange') 
plt.plot(X, fuzzy_union, '--', label='Union (A ∪ B)', color='green') 
plt.plot(X, fuzzy_intersection, '--', label='Intersection (A ∩ B)', color='red') 
plt.plot(X, fuzzy_complement_A, '--', label='Complement (A\')', color='purple') 
plt.plot(X, fuzzy_difference, '--', label='Difference (A - B)', color='brown') 
plt.title('Fuzzy Set Operations') 
plt.xlabel('Universe (X)') 
plt.ylabel('Membership Value') 
plt.legend() 
plt.grid(True) 
plt.show() 
def fuzzy_repr(name, X, M): 
pairs = [f"({x:.1f}, {m:.2f})" for x, m in zip(X[::10], M[::10])] 
return f"{name} = {{ " + ", ".join(pairs) + " }" 
print("\n===== FUZZY SET REPRESENTATIONS =====\n") 
print(fuzzy_repr("A", X, A)) 
print(fuzzy_repr("B", X, B)) 
print(fuzzy_repr("Union (A ∪ B)", X, fuzzy_union)) 
print(fuzzy_repr("Intersection (A ∩ B)", X, fuzzy_intersection)) 
print(fuzzy_repr("Complement (A')", X, fuzzy_complement_A)) 
print(fuzzy_repr("Set Difference (A - B)", X, fuzzy_difference))



++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++



Code for Fuzzy set and its operation: 
import numpy as np 
import skfuzzy as fuzz 
from skfuzzy import control as ctrl 
import matplotlib.pyplot as plt 
# Define fuzzy variables 
temperature = ctrl.Antecedent(np.arange(0, 41, 1), 'temperature')   # 0–40°C 
fan_speed = ctrl.Consequent(np.arange(0, 101, 1), 'fan_speed')      
# 0–100% 
# Define fuzzy membership functions for Temperature 
temperature['cold'] = fuzz.trimf(temperature.universe, [0, 0, 15]) 
temperature['warm'] = fuzz.trimf(temperature.universe, [10, 20, 30]) 
temperature['hot'] = fuzz.trimf(temperature.universe, [25, 40, 40]) 
# Define fuzzy membership functions for Fan Speed 
fan_speed['low'] = fuzz.trimf(fan_speed.universe, [0, 0, 50]) 
fan_speed['medium'] = fuzz.trimf(fan_speed.universe, [25, 50, 75]) 
fan_speed['high'] = fuzz.trimf(fan_speed.universe, [50, 100, 100]) 
# Define fuzzy rules 
rule1 = ctrl.Rule(temperature['cold'], fan_speed['low']) 
rule2 = ctrl.Rule(temperature['warm'], fan_speed['medium']) 
rule3 = ctrl.Rule(temperature['hot'], fan_speed['high']) 
# Build control system 
fan_ctrl_system = ctrl.ControlSystem([rule1, rule2, rule3]) 
fan = ctrl.ControlSystemSimulation(fan_ctrl_system) 
# Test: Set input temperature value 
input_temp = 28 
fan.input['temperature'] = input_temp 
# Compute result 
fan.compute() 
# Display output 
print(f"\n===== FUZZY CONTROLLER SYSTEM =====") 
print(f"Input Temperature : {input_temp}°C") 
print(f"Output Fan Speed  : {fan.output['fan_speed']:.2f}%") 
print("===================================\n") 
# Visualize results 
temperature.view() 
plt.figure() 
fan_speed.view(sim=fan) 
plt.show()


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++




Code for Self-Organizing Maps (SOM): 
import numpy as np 
import matplotlib.pyplot as plt 
from sklearn.datasets import load_iris 
from sklearn.preprocessing import MinMaxScaler 
from minisom import MiniSom 
iris = load_iris() 
X = iris.data 
y = iris.target 
scaler = MinMaxScaler() 
X_scaled = scaler.fit_transform(X) 
som = MiniSom(x=7, y=7, input_len=X_scaled.shape[1], sigma=1.0, learning_rate=0.5) 
som.random_weights_init(X_scaled) 
print("Training SOM...") 
som.train_random(X_scaled, num_iteration=1000) 
print("Training completed.") 
plt.figure(figsize=(8, 8)) 
for i, x in enumerate(X_scaled): 
w = som.winner(x)  # Best Matching Unit (BMU) 
plt.text(w[0] + 0.5, w[1] + 0.5, str(y[i]), 
color=plt.cm.rainbow(y[i] / 2), fontdict={'size': 12, 'weight': 'bold'}) 
plt.xlim([0, som.get_weights().shape[0] + 1]) 
plt.ylim([0, som.get_weights().shape[1] + 1]) 
plt.title("Self-Organizing Map on Iris Dataset") 
plt.show()



+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Code for Supervised Self-Organizing Maps (SSOM): 
import numpy as np 
import matplotlib.pyplot as plt 
from sklearn import datasets 
from sklearn.preprocessing import StandardScaler, OneHotEncoder 
from sklearn.model_selection import train_test_split 
from sklearn.metrics import accuracy_score 
class SSOM: 
def __init__(self, m, n, input_dim, n_classes, lr=0.5, sigma=None): 
self.m, self.n = m, n 
self.grid_size = m * n 
self.input_dim, self.n_classes = input_dim, n_classes 
self.lr0, self.sigma0 = lr, sigma if sigma else max(m, n) / 2 
self.weights = np.random.randn(self.grid_size, input_dim) 
self.label_weights = np.random.randn(self.grid_size, n_classes) * 0.01 
self.coords = np.array([(i, j) for i in range(m) for j in range(n)]) 
def _decay(self, val, epoch, max_epoch): return val * np.exp(-epoch / max_epoch) 
def _bmu(self, x): return np.argmin(np.linalg.norm(self.weights - x, axis=1)) 
def _neigh(self, bmu, sigma): 
d2 = np.sum((self.coords - self.coords[bmu])**2, axis=1) 
return np.exp(-d2 / (2*sigma**2)) 
def fit(self, X, y, epochs=50): 
self.hist = [] 
for e in range(epochs): 
lr, sigma = self._decay(self.lr0, e, epochs), self._decay(self.sigma0, e, epochs) 
for x, yv in zip(X, y): 
bmu = self._bmu(x) 
h = self._neigh(bmu, sigma)[:, None] 
self.weights += lr * h * (x - self.weights) 
self.label_weights += lr * h * (yv - self.label_weights) 
self.hist.append(accuracy_score(np.argmax(y,1), self.predict(X))) 
def predict(self, X): 
return [np.argmax(self.label_weights[self._bmu(x)]) for x in X] 
iris = datasets.load_iris() 
X, y = iris.data, iris.target 
X = StandardScaler().fit_transform(X) 
oh = OneHotEncoder(sparse_output=False) 
y_oh = oh.fit_transform(y.reshape(-1,1)) 
Xtr, Xte, ytr, yte = train_test_split(X, y_oh, test_size=0.3, random_state=42, stratify=y) 
som = SSOM(6, 6, input_dim=X.shape[1], n_classes=3, lr=0.5) 
som.fit(Xtr, ytr, epochs=60) 
ypred = som.predict(Xte) 
print("Test accuracy:", accuracy_score(np.argmax(yte,1), ypred)) 
plt.plot(som.hist) 
plt.xlabel("Epoch"); plt.ylabel("Train accuracy"); plt.title("SSOM training accuracy") 
plt.show()

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++



import random 
 
# 1⃣ Given population of 4 numbers 
population = [5, 9, 12, 15] 
 
# 2⃣ Encode to binary (5 bits) 
encoded_pop = [format(num, '05b') for num in population] 
print("Encoded Population:", encoded_pop) 
 
# --- Helper Functions --- 
 
def single_point_crossover(p1, p2): 
    """Perform single-point crossover""" 
    point = random.randint(1, len(p1) - 2) 
    c1 = p1[:point] + p2[point:] 
    c2 = p2[:point] + p1[point:] 
    print(f"\nSingle Point Crossover at index {point}") 
    return c1, c2 
 
def two_point_crossover(p1, p2): 
    """Perform two-point crossover""" 
    points = sorted(random.sample(range(1, len(p1) - 1), 2)) 
    p1_start, p1_end = points 
    c1 = p1[:p1_start] + p2[p1_start:p1_end] + p1[p1_end:] 
    c2 = p2[:p1_start] + p1[p1_start:p1_end] + p2[p1_end:] 
    print(f"\nTwo Point Crossover between indices {p1_start} and {p1_end}") 
    return c1, c2 
 
def bit_flip_mutation(chromosome, mutation_rate=0.2): 
    """Flip bits randomly""" 
    mutated = '' 
    for bit in chromosome: 
        if random.random() < mutation_rate: 
            mutated += '0' if bit == '1' else '1' 
        else: 
            mutated += bit 
    return mutated 
 
def swap_mutation(chromosome): 
    """Swap two random bits""" 
    i, j = random.sample(range(len(chromosome)), 2) 
    chrom_list = list(chromosome) 
    chrom_list[i], chrom_list[j] = chrom_list[j], chrom_list[i] 
    return "".join(chrom_list) 
 
# 3⃣ Perform Single-Point Crossover (between first two parents) 
p1, p2 = encoded_pop[0], encoded_pop[1] 
child1, child2 = single_point_crossover(p1, p2) 
print("Parents:", p1, p2) 
print("Children:", child1, child2) 
 
# 4⃣ Perform Two-Point Crossover (between last two parents) 
p3, p4 = encoded_pop[2], encoded_pop[3] 
child3, child4 = two_point_crossover(p3, p4) 
print("Parents:", p3, p4) 
print("Children:", child3, child4) 
 
# 5⃣ Apply Two Mutations 
# Mutation 1 → Bit Flip on child1 
mut1 = bit_flip_mutation(child1) 
print("\nAfter Bit Flip Mutation on Child1:", mut1) 
 
# Mutation 2 → Swap Mutation on child3 
mut2 = swap_mutation(child3) 
print("After Swap Mutation on Child3:", mut2) 
# 6⃣ Decode final offspring 
decoded = [int(x, 2) for x in [mut1, child2, mut2, child4]] 
print("\nDecoded New Population:", decoded)
